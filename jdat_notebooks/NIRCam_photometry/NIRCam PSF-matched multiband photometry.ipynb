{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JWST Data Analysis Use Case\n",
    "\n",
    "# NIRCam PSF-matched multiband photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing simulated NIRCam imaging: JADES JWST GTO extragalactic blank field\n",
    "\n",
    "http://fenrir.as.arizona.edu/jwstmock/\n",
    "\n",
    "(Williams et al. 2018)\n",
    "https://ui.adsabs.harvard.edu/abs/2018ApJS..236...33W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use astropy.photutils to detect objects in the simulated F200W image, then measure isophotal photometry in all 9 filters (F090W, F115W, F150W, F200W, F277W, F335M, F356W, F410M, F444W). PSF-matching is required in the long wavelength channel filters, so we degrade F200W to the redder wavelength filters, and perform PSF corrections.\n",
    "\n",
    "We demonstrate loading the catalog back in and doing some simple analysis of the full catalog and of an individual galaxy. We show the PSF-matching accurately corrects colors on average, and individually for one galaxy, matching the input simulated SED.\n",
    "\n",
    "Here we analyze only the central 1000 x 1000 pixels (30\" x 30\") of the full JADES simulation. These cutouts have been staged at STScI with permission from the authors (Williams et al.).\n",
    "\n",
    "NOTE: The simulated JADES images have different units (e-/s) than JWST pipeline products (MJy/sr).\n",
    "\n",
    "NOTE: An exposure map is missing but required to calculate flux uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "* Check accuracy of photometry against simulated JADES catalog\n",
    "* Exposure map required for input to error calculation\n",
    "* ABmag units cannot be written to ecsv file (astropy update coming soon)\n",
    "* plot with text labels looks horrible (I wish cursor hover would show id number instead)\n",
    "* Fix plot secondary axis: mag vs. flux\n",
    "* requirements.txt file -- but I don't know what versions are \"required\"\n",
    "* Robel's previous comments: https://github.com/spacetelescope/dat_pyinthesky/pull/82#pullrequestreview-355206337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "import astropy.wcs as wcs\n",
    "from astropy.table import QTable\n",
    "import astropy.units as u\n",
    "from astropy.visualization import make_lupton_rgb, SqrtStretch, LogStretch, hist\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "\n",
    "import photutils\n",
    "print('photutils', photutils.__version__)\n",
    "from photutils import Background2D, MedianBackground, detect_sources, deblend_sources, source_properties\n",
    "from photutils.utils import calc_total_error\n",
    "\n",
    "from photutils.psf.matching import resize_psf\n",
    "from photutils import CosineBellWindow, create_matching_kernel\n",
    "from astropy.convolution import convolve #, Gaussian2DKernel, Tophat2DKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of images to be loaded and analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/nircam_photometry/'\n",
    "\n",
    "filters = 'F090W F115W F150W F200W F277W F335M F356W F410M F444W'.split()\n",
    "\n",
    "# Data images [e-/s]\n",
    "image_files = {}\n",
    "for filt in filters:\n",
    "    filename = f'jades_jwst_nircam_goods_s_crop_{filt}.fits'\n",
    "    image_files[filt] = os.path.join(input_file_url, filename)\n",
    "\n",
    "# Weight images (Inverse Variance Maps; IVM)\n",
    "weight_files = {}\n",
    "for filt in filters:\n",
    "    filename = f'jades_jwst_nircam_goods_s_crop_{filt}_wht.fits'\n",
    "    weight_files[filt] = os.path.join(input_file_url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load detection image: F200W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = 'F200W'\n",
    "infile = image_files[filt]\n",
    "hdu = fits.open(infile)\n",
    "data = hdu[0].data\n",
    "imwcs = wcs.WCS(hdu[0].header, hdu)\n",
    "\n",
    "weight = fits.open(weight_files[filt])[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report image size and field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny, nx = data.shape\n",
    "#pixscale = np.abs(hdu[0].header['CD1_1']) * 3600\n",
    "pixscale = wcs.utils.proj_plane_pixel_scales(imwcs)[0] \n",
    "pixscale *= imwcs.wcs.cunit[0].to('arcsec')\n",
    "outline = '%d x %d pixels' % (ny, nx)\n",
    "outline += ' = %g\" x %g\"' % (ny * pixscale, nx * pixscale)\n",
    "outline += ' (%.2f\" / pixel)' % pixscale\n",
    "print(outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create color images (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 NIRCam short wavelength channel images\n",
    "r = fits.open(image_files['F200W'])[0].data\n",
    "g = fits.open(image_files['F150W'])[0].data\n",
    "b = fits.open(image_files['F090W'])[0].data\n",
    "rgb_sw = make_lupton_rgb(r, g, b, Q=5, stretch=0.02) # , minimum=-0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 NIRCam long wavelength channel images\n",
    "r = fits.open(image_files['F444W'])[0].data\n",
    "g = fits.open(image_files['F356W'])[0].data\n",
    "b = fits.open(image_files['F277W'])[0].data\n",
    "\n",
    "rgb_lw = make_lupton_rgb(r, g, b, Q=5, stretch=0.02) # , minimum=-0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5,4))\n",
    "\n",
    "ax_sw = fig.add_subplot(1, 2, 1, projection=imwcs)#, sharex=True, sharey=True)\n",
    "ax_sw.imshow(rgb_sw, origin='lower')\n",
    "ax_sw.set_xlabel('Right Ascension')\n",
    "ax_sw.set_ylabel('Declination')\n",
    "ax_sw.set_title('Short Wavelength Channel')\n",
    "\n",
    "ax_lw = fig.add_subplot(1, 2, 2, projection=imwcs, sharex=ax_sw, sharey=ax_sw)\n",
    "ax_lw.imshow(rgb_lw, origin='lower')\n",
    "ax_lw.set_xlabel('Right Ascension')\n",
    "ax_lw.set_title('Long Wavelength Channel')\n",
    "#ax_lw.set(yticklabels=[])  # this didn't work\n",
    "\n",
    "#plt.subplots_adjust(left=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Sources and Deblend using astropy.photutils\n",
    "https://photutils.readthedocs.io/en/latest/segmentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For detection, requiring 5 connected pixels 2-sigma above background\n",
    "\n",
    "# Measure background and set detection threshold\n",
    "bkg_estimator = MedianBackground()\n",
    "bkg = Background2D(data, (50, 50), filter_size=(3, 3), bkg_estimator=bkg_estimator)\n",
    "threshold = bkg.background + (2. * bkg.background_rms)\n",
    "\n",
    "# Before detection, smooth image with Gaussian FWHM = 3 pixels\n",
    "sigma = 3.0 * gaussian_fwhm_to_sigma  \n",
    "kernel = Gaussian2DKernel(sigma, x_size=3, y_size=3)\n",
    "kernel.normalize()\n",
    "\n",
    "# Detect and deblend\n",
    "segm_detect  = detect_sources(data, threshold, npixels=5, filter_kernel=kernel)\n",
    "segm_deblend = deblend_sources(data, segm_detect, npixels=5, filter_kernel=kernel, nlevels=32, contrast=0.001)\n",
    "\n",
    "# Save segmentation map of detected objects\n",
    "segm_hdu = fits.PrimaryHDU(segm_deblend.data.astype(np.uint32), header=imwcs.to_header())\n",
    "segm_hdu.writeto('JADES_detections_segm.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure photometry (and more) in detection image\n",
    "https://photutils.readthedocs.io/en/latest/segmentation.html#centroids-photometry-and-morphological-properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error = bkg.background_rms\n",
    "# Input weight should be exposure map. Fudging for now.\n",
    "error = calc_total_error(data, bkg.background_rms, weight/500)  # fudge\n",
    "cat = source_properties(data-bkg.background, segm_deblend, wcs=imwcs, background=bkg.background, error=error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show detections alongside images (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(9.5,6))\n",
    "# For RA,Dec axes instead of pixels, add: , subplot_kw={'projection': imwcs})\n",
    "\n",
    "# Color image\n",
    "ax[0,0].imshow(rgb_sw, origin='lower')\n",
    "ax[0,0].set_title('Color Image')\n",
    "\n",
    "# Data\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "ax[0,1].imshow(data, origin='lower', cmap='Greys_r', norm=norm, vmin=0)\n",
    "ax[0,1].set_title('Detection Image F200W')\n",
    "\n",
    "# Segmentation map\n",
    "cmap = segm_deblend.make_cmap(seed=12345)  # ERROR\n",
    "ax[0,2].imshow(segm_deblend, origin='lower', cmap=cmap)\n",
    "ax[0,2].set_title('Detections (Segmentation Image)')\n",
    "\n",
    "# Weight\n",
    "#norm = ImageNormalize(stretch=SqrtStretch())\n",
    "ax[1,0].imshow(weight, origin='lower', cmap='Greys_r', vmin=0)\n",
    "ax[1,0].set_title('Weight Image F200W')\n",
    "\n",
    "# RMS\n",
    "norm = ImageNormalize()\n",
    "ax[1,1].imshow(bkg.background_rms, origin='lower', norm=norm)\n",
    "ax[1,1].set_title('Background RMS')\n",
    "\n",
    "# Total error including Poisson noise\n",
    "ax[1,2].imshow(error, origin='lower', norm=norm)\n",
    "ax[1,2].set_title('RMS + Poisson noise')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View all measured quantities in detection image (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep some quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 'id xcentroid ycentroid sky_centroid area semimajor_axis_sigma semiminor_axis_sigma ellipticity orientation gini'.split()\n",
    "tbl = cat.to_table(columns=columns)\n",
    "tbl.rename_column('semimajor_axis_sigma', 'a')\n",
    "tbl.rename_column('semiminor_axis_sigma', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert measured fluxes (data units) to magnitudes\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/equivalencies.html#photometric-zero-point-equivalency\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/logarithmic_units.html#logarithmic-units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not detected: mag =  99; magerr = 1-sigma upper limit assuming zero flux\n",
    "# not observed: mag = -99; magerr = 0\n",
    "def fluxes2mags(flux, fluxerr):\n",
    "    nondet = flux < 0  # Non-detection if flux is negative\n",
    "    unobs = (fluxerr <= 0) + (fluxerr == np.inf)  # Unobserved if flux uncertainty is negative or infinity\n",
    "\n",
    "    mag = flux.to(u.ABmag)\n",
    "    magupperlimit = fluxerr.to(u.ABmag) # 1-sigma upper limit if flux=0\n",
    "\n",
    "    mag = np.where(nondet, 99 * u.ABmag, mag)\n",
    "    mag = np.where(unobs, -99 * u.ABmag, mag)\n",
    "\n",
    "    magerr = 2.5 * np.log10(1 + fluxerr/flux) \n",
    "    magerr = magerr.value * u.ABmag\n",
    "\n",
    "    magerr = np.where(nondet, magupperlimit, magerr)\n",
    "    magerr = np.where(unobs, 0*u.ABmag, magerr)\n",
    "    \n",
    "    return mag, magerr\n",
    "\n",
    "# Includes features I couldn't find in astropy:\n",
    "# mag = 99 / -99 for non-detections / unobserved\n",
    "# flux uncertainties -> mag uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiband photometry using isophotal apertures defined in detection image\n",
    "(Similar to running SourceExtractor in double-image mode)  \n",
    "(No PSF corrections just yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 'F090W F115W F150W F200W F277W F335M F356W F410M F444W'.split()\n",
    "for filt in filters:\n",
    "    infile = image_files[filt]\n",
    "    print(filt)\n",
    "    print(infile)\n",
    "    print(weight_files[filt])\n",
    "    hdu = fits.open(infile)\n",
    "    data = hdu[0].data\n",
    "    zp = hdu[0].header['ABMAG'] * u.ABmag  # zeropoint\n",
    "    weight = fits.open(weight_files[filt])[0].data\n",
    "    \n",
    "    # Measure background\n",
    "    bkg = Background2D(data, (50, 50), filter_size=(3, 3), bkg_estimator=bkg_estimator)\n",
    "    #error = bkg.background_rms\n",
    "    error = calc_total_error(data, bkg.background_rms, weight/500) # fudge\n",
    "                             \n",
    "    # Measure properties in each image of previously detected objects \n",
    "    filtcat = source_properties(data-bkg.background, segm_deblend, wcs=imwcs, background=bkg.background, error=error)\n",
    "\n",
    "    # Convert measured fluxes to fluxes in nJy and to AB magnitudes\n",
    "    filttbl = filtcat.to_table()\n",
    "    tbl[filt+'_flux']    = flux    = filttbl['source_sum']     * zp.to(u.nJy)\n",
    "    tbl[filt+'_fluxerr'] = fluxerr = filttbl['source_sum_err'] * zp.to(u.nJy)\n",
    "\n",
    "    mag, magerr = fluxes2mags(flux, fluxerr)\n",
    "    #mag = mag * u.ABmag  # incompatible with file writing\n",
    "    tbl[filt+'_mag']    = mag.value\n",
    "    tbl[filt+'_magerr'] = magerr.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View complete results (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save photometry as output catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbl.write('JADESphotometry.ecsv', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat JADESphotometry.ecsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PSFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download and unpack the tar files available here:  \n",
    "https://jwst-docs.stsci.edu/near-infrared-camera/nircam-predicted-performance/nircam-point-spread-functions#NIRCamPointSpreadFunctions-SimulatedNIRCamPSFs  \n",
    "PSFs_SW_filters: https://stsci.box.com/s/s2lepxr9086gq4sogr3kwftp54n1c5vl  \n",
    "PSFs_LW_filters: https://stsci.box.com/s/gzl7blxb1k3p4n66gs7jvt7xorfrotyb  \n",
    "Each FITS file contains:  \n",
    "– hdu[0]: a 4x oversampled PSF  \n",
    "– hdu[1]: PSF at detector pixel scale (0.031\" and 0.063\" in the short and long wavelength channels, respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_inputs = {}\n",
    "PSF_images = {}\n",
    "\n",
    "image_pixel_scale = pixscale  # 0.03\" / pix\n",
    "detector_pixel_scales = {'SW':0.031, 'LW':0.063}\n",
    "\n",
    "PSF_url = os.path.join(input_file_url, 'NIRCam_PSFs')\n",
    "\n",
    "for i, filt in enumerate(filters):\n",
    "    lam = int(filt[1:4]) / 100\n",
    "    if lam < 2.4:\n",
    "        channel = 'SW'\n",
    "    else:\n",
    "        channel = 'LW'\n",
    "\n",
    "    # Load PSF\n",
    "    PSF_file = 'PSF_%scen_G5V_fov299px_ISIM41.fits' % filt\n",
    "    #PSF_file = os.path.join('NIRCam_PSFs_' + channel, PSF_file)\n",
    "    PSF_file = os.path.join(PSF_url, PSF_file)\n",
    "\n",
    "    print(PSF_file)\n",
    "    PSF_hdu = fits.open(PSF_file)\n",
    "    PSF_inputs[filt] = data = PSF_hdu[1].data  # 2nd extension is at pixel scale (not oversampled)\n",
    "    #imwcs = wcs.WCS(hdu[0].header, hdu)\n",
    "    ny, nx = data.shape\n",
    "    \n",
    "    # Resize from detector pixel scale to image pixel scale (here 0.03\" / pix)\n",
    "    detector_pixel_scale = detector_pixel_scales[channel]\n",
    "    ny_resize = ny * detector_pixel_scale / image_pixel_scale  # Assume square PSF (ny = nx)\n",
    "    ny_resize = np.round(ny_resize)\n",
    "    ny_resize = np.int((ny_resize // 2) * 2 + 1)  # Make it an odd number of pixels to ensure PSF is centered\n",
    "    PSF_pixel_scale = ny_resize / ny * image_pixel_scale    \n",
    "    PSF_image = resize_psf(PSF_inputs[filt], PSF_pixel_scale, image_pixel_scale)  # Resize PSF here\n",
    "    r = (ny_resize - ny) // 2\n",
    "    PSF_images[filt] = PSF = PSF_image[r:-r,r:-r]  # Trim to same size as input PSFs\n",
    "    #print(filt, ny, ny_resize, PSF_image.shape, PSF_images[filt].shape, PSF_pixel_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF Matching \n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/psf_matching.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine PSF convolution kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show PSFs (optional)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(filters), figsize=(9.5,1.5), sharex=True, sharey=True)\n",
    "\n",
    "r = 15\n",
    "for i, filt in enumerate(filters):\n",
    "    data = PSF_images[filt]\n",
    "    ny, nx = data.shape\n",
    "    yc = ny // 2\n",
    "    xc = nx // 2\n",
    "    stamp = data[yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    norm = ImageNormalize(stretch=LogStretch())  # scale each filter individually\n",
    "    ax[i].imshow(stamp, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    ax[i].set_title(filt.upper())\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_kernels = {}\n",
    "reference_filter = 'F200W'\n",
    "reference_PSF = PSF_images[reference_filter]\n",
    "i_reference = filters.index(reference_filter)\n",
    "window = CosineBellWindow(alpha=0.35)\n",
    "for filt in filters[i_reference+1:]:\n",
    "    PSF_kernels[filt] = PSF_matching_kernel = create_matching_kernel(reference_PSF, PSF_images[filt], window=window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolve PSFs and compare to actual (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSFs_convolved = {}\n",
    "for filt in filters[i_reference+1:]:\n",
    "    PSF = PSF_images[reference_filter][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    kernel = PSF_kernels[filt][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    PSFs_convolved[filt] = convolve(PSF, kernel)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_profile(PSF):\n",
    "    data = PSF\n",
    "    ny, nx = data.shape\n",
    "    yc = ny // 2\n",
    "    xc = nx // 2\n",
    "    y, x = np.indices(data.shape)\n",
    "    rr = np.sqrt((x-xc)**2 + (y-yc)**2)\n",
    "    ii = np.argsort(rr.flat)\n",
    "    rr = rr.flat[ii]\n",
    "    yy = data.flat[ii]\n",
    "    return rr, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plot_colors = [mpl_colors[i] for i in (0,6,1)]\n",
    "\n",
    "plot_filters = filters[i_reference:]\n",
    "ncolumns = len(plot_filters)\n",
    "\n",
    "fig, ax = plt.subplots(4, ncolumns, figsize=(9.5,7))#, sharex=True, sharey=True)\n",
    "\n",
    "for i, filt in enumerate(plot_filters):\n",
    "    # Input PSF on top row\n",
    "    ny, nx = PSF_images[filt].shape\n",
    "    yc = ny // 2\n",
    "    xc = nx // 2    \n",
    "    stamp = PSF_images[filt][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())  # scale each stamp individually\n",
    "    ax[0,i].imshow(stamp, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    ax[0,i].set_title(filt.upper())\n",
    "\n",
    "    rr, yy = radial_profile(stamp)\n",
    "    ax[3,i].plot(rr, yy, color=plot_colors[0], alpha=0.7)\n",
    "    ax[3,i].set_xlim(0,r)\n",
    "    ax[3,i].set_ylim(0,0.05)\n",
    "\n",
    "    for j in range(4):\n",
    "        ax[j,i].get_xaxis().set_ticks([])\n",
    "        ax[j,i].get_yaxis().set_ticks([])\n",
    "\n",
    "    if i == 0:\n",
    "        # Plot F200W profile everywhere for comparison\n",
    "        for icolumn in range(ncolumns):\n",
    "            ax[3,icolumn].plot(rr, yy, color='g', lw=0) # hidden with lw=0\n",
    "        continue\n",
    "        \n",
    "    # Kernels\n",
    "    kernel = PSF_kernels[filt][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())  # scale each stamp individually\n",
    "    ax[1,i].imshow(kernel, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    \n",
    "    rr, yy = radial_profile(kernel)\n",
    "    ax[3,i].plot(rr, yy, color=plot_colors[1], alpha=0.7, lw=0) # hidden with lw=0\n",
    "\n",
    "    # Convolved PSFs\n",
    "    stamp = PSFs_convolved[filt]\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())  # scale each stamp individually\n",
    "    ax[2,i].imshow(stamp, cmap='Greys_r', norm=norm, origin='lower')\n",
    "\n",
    "    rr, yy = radial_profile(stamp)\n",
    "    ax[3,i].plot(rr, yy, color=plot_colors[2], alpha=0.7)\n",
    "\n",
    "ax[0,0].set_ylabel('PSF', color=plot_colors[0])\n",
    "ax[1,0].set_ylabel('Kernel', color=plot_colors[1])\n",
    "ax[2,0].set_ylabel('Convolved', color=plot_colors[2])\n",
    "ax[3,0].set_ylabel('Radial Profiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolve F200W detection image to Long Wavelength PSFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_image_hdu = fits.open(image_files[reference_filter])\n",
    "reference_image_data = reference_image_hdu[0].data[:]\n",
    "\n",
    "for filt in filters[i_reference+1:]:\n",
    "    output_filter = filt\n",
    "    output_image = 'jades_convolved_%s_to_%s.fits' % (reference_filter, output_filter)\n",
    "    if os.path.exists(output_image):\n",
    "        print(output_image, 'EXISTS')\n",
    "    else:\n",
    "        print(output_filter + '...')\n",
    "        PSF_kernel = PSF_kernels[filt][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "        convolved_image = convolve(reference_image_data, PSF_kernel)\n",
    "        reference_image_hdu[0].data = convolved_image\n",
    "        print('SAVING %s' % output_image)\n",
    "        reference_image_hdu.writeto(output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiband photometry in convolved images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filt in filters[i_reference+1:]:\n",
    "    infile = 'jades_convolved_%s_to_%s.fits' % (reference_filter, output_filter)\n",
    "    print(filt)\n",
    "    print(infile)\n",
    "    print(weight_files[filt])\n",
    "    hdu = fits.open(infile)\n",
    "    data = hdu[0].data\n",
    "    zp = hdu[0].header['ABMAG'] * u.ABmag  # zeropoint\n",
    "    weight = fits.open(weight_files[filt])[0].data\n",
    "    \n",
    "    # Measure background\n",
    "    bkg = Background2D(data, (50, 50), filter_size=(3, 3), bkg_estimator=bkg_estimator)\n",
    "    #error = bkg.background_rms\n",
    "    error = calc_total_error(data, bkg.background_rms, weight/500)  # 500 fudge\n",
    "    # Should handle uncertainties better! (also for regular images...)\n",
    "                             \n",
    "    # Measure properties in each image of previously detected objects \n",
    "    filtcat = source_properties(data-bkg.background, segm_deblend, wcs=imwcs, background=bkg.background, error=error)\n",
    "\n",
    "    # Convert measured fluxes to fluxes in nJy and to AB magnitudes\n",
    "    filttbl = filtcat.to_table()\n",
    "    tbl['convolved_to_'+filt+'_flux']    = flux    = filttbl['source_sum']     * zp.to(u.nJy)\n",
    "    tbl['convolved_to_'+filt+'_fluxerr'] = fluxerr = filttbl['source_sum_err'] * zp.to(u.nJy)\n",
    "\n",
    "    mag, magerr = fluxes2mags(flux, fluxerr)\n",
    "    #mag = mag * u.ABmag  # incompatible with file writing\n",
    "    tbl['convolved_to_'+filt+'_mag']    = mag.value\n",
    "    tbl['convolved_to_'+filt+'_magerr'] = magerr.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnitude corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "tbl_without_corrections = deepcopy(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct magnitudes in place (so only run this cell once!)\n",
    "# mag_corrected = mag + det_mag - det_blurry_mag\n",
    "\n",
    "for filt in filters[i_reference+1:]:\n",
    "    reference_magnitudes = tbl[reference_filter+'_mag']\n",
    "    blurred_magnitudes = tbl['convolved_to_'+filt+'_mag']\n",
    "    magnitude_corrections = reference_magnitudes - blurred_magnitudes\n",
    "    filter_magnitudes = tbl[filt+'_mag']\n",
    "    corrected_magnitudes = filter_magnitudes + magnitude_corrections\n",
    "    good_magnitudes = np.less(filter_magnitudes, 90) * np.greater(filter_magnitudes, 0)\n",
    "    corrected_magnitudes = np.where(good_magnitudes, corrected_magnitudes, filter_magnitudes)\n",
    "\n",
    "    reference_fluxes = tbl[reference_filter+'_flux']\n",
    "    flux_corrections = 10 ** (-0.4 * magnitude_corrections)\n",
    "    flux_corrections = np.where(good_magnitudes, flux_corrections, 1)\n",
    "    filter_fluxes = tbl[filt+'_flux']\n",
    "    corrected_fluxes = filter_fluxes * flux_corrections\n",
    "\n",
    "    tbl[filt+'_flux'] = corrected_fluxes     # Upddating in place! (so only run this once)\n",
    "    tbl[filt+'_mag'] = corrected_magnitudes  # Upddating in place! (so only run this once)\n",
    "    tbl[filt+'_flux_PSFcor'] = flux_corrections\n",
    "    tbl[filt+'_mag_PSFcor']  = magnitude_corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat output catalog for readability (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove units (pixels) from area\n",
    "tbl['area'] = tbl['area'].value.astype(int)\n",
    "\n",
    "# Replace sky_centroid with ra, dec\n",
    "tbl['ra'] = tbl['sky_centroid'].ra.degree\n",
    "tbl['dec'] = tbl['sky_centroid'].dec.degree\n",
    "\n",
    "columns = list(tbl.columns)\n",
    "columns = columns[:3] + ['ra', 'dec'] + columns[4:-2]\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    if column.endswith('flux'):\n",
    "        break\n",
    "\n",
    "columns = columns[:i]\n",
    "\n",
    "for filt in filters:\n",
    "    columns.append(filt+'_flux')\n",
    "    columns.append(filt+'_fluxerr')\n",
    "    columns.append(filt+'_mag')\n",
    "    columns.append(filt+'_magerr')\n",
    "    #column = filt+'_flux_PSF-correction'\n",
    "    column = filt+'_flux_PSFcor'\n",
    "    if column in list(tbl.columns):\n",
    "        columns.append(column)\n",
    "        columns.append(filt+'_mag_PSFcor')\n",
    "        \n",
    "tbl = tbl[columns]\n",
    "\n",
    "for column in columns:\n",
    "    tbl[column].info.format = '.4f'\n",
    "\n",
    "tbl['ra'].info.format = '11.7f'\n",
    "tbl['dec'].info.format = ' 11.7f'\n",
    "\n",
    "tbl['id'].info.format = 'd'\n",
    "tbl['area'].info.format = 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.write('JADES_photometry.ecsv', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.write('JADES_photometry.cat', format='ascii.fixed_width_two_line', delimiter=' ', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat JADES_photometry.cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start new session and analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load catalog and segmentation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catalog: ecsv format preserves units for loading in Python notebooks\n",
    "tbl = QTable.read('JADES_photometry.ecsv')\n",
    "\n",
    "# Reconstitute filter list\n",
    "filters = []\n",
    "for param in tbl.columns:\n",
    "    if param[-4:] == '_mag':\n",
    "        filters.append(param[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation map\n",
    "segmfile = 'JADES_detections_segm.fits'\n",
    "segm = fits.open(segmfile)[0].data\n",
    "segm = photutils.segmentation.SegmentationImage(segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input simulation JADES JAGUAR catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "if 1:\n",
    "    # Already performed cropping of 302,515 simulated galaxies down to 653\n",
    "    # in the smaller images used in this demo\n",
    "    input_catalog_file = os.path.join(input_file_url, 'JADES_SF_mock_r1_v1.1_crop.fits.gz')\n",
    "    simulated_catalog = Table.read(input_catalog_file)\n",
    "else:\n",
    "    full_simulated_catalog = Table.read('JADES_SF_mock_r1_v1.1.fits.gz')\n",
    "\n",
    "    RArange  = 53.16879, 53.1782\n",
    "    DECrange = -27.805394, -27.797069\n",
    "\n",
    "    good1 = simcat['RA'] > RArange[0]\n",
    "    good2 = simcat['RA'] < RArange[1]\n",
    "    good3 = simcat['DEC'] > DECrange[0]\n",
    "    good4 = simcat['DEC'] < DECrange[1]\n",
    "    all_good = good1 * good2 * good3 * good4\n",
    "\n",
    "    simulated_catalog = full_simulated_catalog[all_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match objects to photutils catalog\n",
    "# https://docs.astropy.org/en/stable/coordinates/matchsep.html\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "coordsim = SkyCoord(ra=simulated_catalog['RA']*u.degree, dec=simulated_catalog['DEC']*u.degree)\n",
    "#coorddet = tbl['sky_centroid']  # Photutils detection catalog\n",
    "coorddet = SkyCoord(ra=tbl['ra']*u.degree, dec=tbl['dec']*u.degree)\n",
    "#idx, d2d, d3d = coordsim.match_to_catalog_sky(coorddet)\n",
    "idx, d2d, d3d = coorddet.match_to_catalog_sky(coordsim)  # Match photutils to input catalog\n",
    "\n",
    "# Only keep close matches\n",
    "d = d2d / u.degree * 3600  # arcsec\n",
    "goodmatch = d < 0.036\n",
    "\n",
    "simid = simulated_catalog[idx]['ID']\n",
    "simid = np.where(goodmatch, simid, -1)\n",
    "\n",
    "zsim = simulated_catalog[idx]['redshift']\n",
    "zsim = np.where(goodmatch, zsim, -1)\n",
    "\n",
    "#magtbl['simid'] = simid\n",
    "#magtbl['matchdist'] = d\n",
    "#magtbl['zsim'] = zsim\n",
    "#magtbl.write('JADEScropz.cat', format='ascii.fixed_width_two_line', delimiter=' ', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color-Magnitude Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mplcursors\n",
    "# Would love a better solution here!\n",
    "\n",
    "filt1, filt2 = 'F200W F444W'.split()\n",
    "\n",
    "mag1 = tbl[filt1+'_mag']\n",
    "mag2 = tbl[filt2+'_mag']\n",
    "\n",
    "# Only plot detections\n",
    "det1 = (0 < mag1) & (mag1 < 90)\n",
    "det2 = (0 < mag2) & (mag2 < 90)\n",
    "det = det1 * det2\n",
    "\n",
    "mag1 = mag1[det]\n",
    "mag2 = mag2[det]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.plot(mag2, mag1-mag2, '.')\n",
    "\n",
    "plt.xlim(plt.xlim()[::-1])\n",
    "\n",
    "plt.xlabel(filt2 + ' AB magnitude')\n",
    "plt.ylabel(filt1 + '  $-$  ' + filt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input vs. Output Color\n",
    "\n",
    "filt1, filt2 = 'F200W F444W'.split()\n",
    "#filt1, filt2 = 'F115W F200W'.split()\n",
    "#filt1, filt2 = 'F277W F444W'.split()\n",
    "#filt1, filt2 = 'F200W F277W'.split()\n",
    "\n",
    "input_flux1  = simulated_catalog['NRC_%s_fnu'%filt1][idx][goodmatch]\n",
    "input_flux2  = simulated_catalog['NRC_%s_fnu'%filt2][idx][goodmatch]\n",
    "\n",
    "input_mag1 = (input_flux1 * u.nJy).to(u.ABmag).value\n",
    "input_mag2 = (input_flux2 * u.nJy).to(u.ABmag).value\n",
    "\n",
    "\n",
    "output_mag1 = tbl[filt1+'_mag'][goodmatch]\n",
    "output_mag2 = tbl[filt2+'_mag'][goodmatch]\n",
    "\n",
    "# Only plot detections\n",
    "det1 = (0 < output_mag1) & (output_mag1 < 90)\n",
    "det2 = (0 < output_mag2) & (output_mag2 < 90)\n",
    "det = det1 * det2\n",
    "\n",
    "output_mag1 = output_mag1[det]\n",
    "output_mag2 = output_mag2[det]\n",
    "\n",
    "input_color  = input_mag1  - input_mag2\n",
    "output_color = output_mag1 - output_mag2\n",
    "\n",
    "output_mag1_uncor = output_mag1 #- tbl[filt1+'_mag_PSFcor'][goodmatch][det]\n",
    "output_mag2_uncor = output_mag2 - tbl[filt2+'_mag_PSFcor'][goodmatch][det]\n",
    "output_color_uncor = output_mag1_uncor - output_mag2_uncor\n",
    "\n",
    "plot_min, plot_max = -1, 1\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(input_color, output_color_uncor, 'r.', alpha=0.5, label='uncorrected')\n",
    "plt.plot(input_color, output_color,       'bo', alpha=0.5, label='PSF corrected')\n",
    "\n",
    "plt.plot([plot_min, plot_max], [plot_min, plot_max])\n",
    "\n",
    "plt.xlabel('Input  '  + filt1 + '  $-$  ' + filt2)\n",
    "plt.ylabel('Output  ' + filt1 + '  $-$  ' + filt2)\n",
    "plt.title('JADES photometry colors: simulated vs. photutils')\n",
    "plt.legend()\n",
    "#plt.savefig('JADES_color_%s-%s.png' % (filt1, filt2))\n",
    "\n",
    "# Only significant effect is measuring long vs. short wavelength colors\n",
    "# then output color is bluer because more red light is lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Spectral Energy Distribution (SED) for one object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select by ID number\n",
    "id = 261 # F090W dropout\n",
    "input_obj  = simulated_catalog[idx][id-1]\n",
    "output_obj = tbl[id-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measured flux does not recover total input flux\n",
    "# Given known simulation input, determine what fraction of the flux was recovered\n",
    "# (for comparison to true values plotted below)\n",
    "\n",
    "input_fluxes = np.array([input_obj['NRC_%s_fnu'%filt] for filt in filters])\n",
    "output_fluxes = np.array([output_obj[filt+'_flux'].value for filt in filters])\n",
    "output_flux_errs = np.array([output_obj[filt+'_fluxerr'].value for filt in filters])\n",
    "\n",
    "# Benitez+00 Equations 8 & 9\n",
    "FOT = np.sum(input_fluxes * output_fluxes / output_flux_errs**2)\n",
    "FTT = np.sum(input_fluxes**2 / output_flux_errs**2)\n",
    "flux_scale_factor = FOT / FTT  # a_m\n",
    "flux_scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select by ID number\n",
    "id = 261 # F090W dropout\n",
    "input_obj  = simulated_catalog[idx][id-1]\n",
    "output_obj = tbl[id-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "flux_factor = 1 / flux_scale_factor\n",
    "for i, filt in enumerate(filters):\n",
    "    input_flux  = input_obj['NRC_%s_fnu'%filt]    \n",
    "    output_flux = output_obj[filt+'_flux'].value\n",
    "    output_flux_err = output_obj[filt+'_fluxerr'].value\n",
    "\n",
    "    lam = int(filt[1:4]) / 100\n",
    "    label=['input fluxes', None][i>0]\n",
    "    plt.plot(lam, input_flux, marker='.', c=mpl_colors[0], label=label)\n",
    "    label=['measured PSF-corrected fluxes $\\\\times$ %.1f' % flux_factor, None][i>0]\n",
    "    plt.errorbar(lam, output_flux*flux_factor, output_flux_err*flux_factor, marker='s', c=mpl_colors[1], alpha=0.5, label=label)\n",
    "    \n",
    "    PSFcor_column = filt+'_flux_PSFcor'\n",
    "    if PSFcor_column in list(output_obj.columns):\n",
    "        output_flux_uncor = output_flux / output_obj[PSFcor_column]\n",
    "        label=['measured uncorrected fluxes $\\\\times$ %.1f' % flux_factor, None][i>i_reference+1]\n",
    "        plt.errorbar(lam, output_flux_uncor * flux_factor, output_flux_err*flux_factor, marker='s', c='r', alpha=0.5, label=label)\n",
    "\n",
    "plt.axhline(0, c='k', ls=':')\n",
    "plt.xlim(0,5)\n",
    "plt.xlabel('Wavelength ($\\mu$m)')\n",
    "plt.ylabel('Flux (nJy)')\n",
    "plt.ylim(10, 70)\n",
    "plt.semilogy()\n",
    "plt.legend()\n",
    "plt.title('JADES SED PSF-corrected')\n",
    "#plt.savefig('JADES photutils SED.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
